---
layout: home
permalink: /teaching/
---

<nav>
    <ul>
      <li><a href="{% link index.markdown %}">Home</a></li>
      <li><a href="/research/">Research</a></li>
      <li><a href="/teaching/">Teaching</a></li>
    </ul>
</nav>
---

# Teaching

<br>


## Useful Resources


[[R Tutorial & Collection of Useful Commands]](FilesToAdd/R-Tutorial.html){:target="_blank"}

<a href="{% link page_teaching_PhDapps.markdown %}"> [PhD Applications & "Swiss Scholarships"] </a>

<!--
<li><a href="/t_PhDapps/">PhDapps</a></li>
-->

<br>


## Courses I Teach/Taught


<div class="tooltip"> <pptt> Econometrics I </pptt> (Master, core course) <br> <jjj>(Fall 2024)</jjj>
</div>
<abstr>
  This is the first of the two compulsory econometrics courses for first year master students. It starts with discussing the basics of probability theory and statistical inference (point estimation, hypothesis testing, uncertainty quantification). It then proceeds to the Ordinary Least Squares (OLS) estimation of the linear regression model, whereby it introduces asymptotic analysis. Finally, the course discusses Maximum Likelihood (ML) estimation, as applied to the linear regression model as well as to other models, like models of binary and censored outcomes, sample selection models, duration models, etc. This includes a discussion of numerical optimization methods and asymptotic properties of ML obtained via extremum estimation theory. Assessment is based on two exams and bi-weekly problem sets. By analyzing foundational models and concepts in-depth and emphasizing the practical (numerical) implementation of inference procedures, the course allows students to easily apply their knowledge to non-standard settings, tailored to their application of interest.
</abstr>

<br>

<div class="tooltip"> <pptt> Econometrics II </pptt> (Master, core course) <br> <jjj>(Spring 2024, 2025)</jjj>
</div>
<abstr>
This is the second of the two compulsory econometrics courses for first year master students. It starts by discussing Instrumental Variables (IV) and Generalized Method of Moments (GMM) estimation. It then introduces Bayesian inference and applies it to the linear regression model (yielding Ridge- and Lasso-estimation and providing the basis of Machine Learning methods). This includes a discussion of numerical sampling methods. Finally, the course discusses univariate time series models -- estimated using both frequentist (OLS, ML) and Bayesian methods -- as as well as the basics of panel data models (pooled OLS, fixed effects, random effects, and correlated random effects). Assessment is based on two exams and bi-weekly problem sets. By analyzing foundational models and concepts in-depth and emphasizing the practical (numerical) implementation of inference procedures, the course allows students to easily apply their knowledge to non-standard settings, tailored to their application of interest.
</abstr>

<br>

<div class="tooltip"> <pptt> Topics in Econometrics </pptt> (Master, elective course) <br> <jjj>(Fall 2023, 2024)</jjj>
</div>
<abstr>
This course discusses further topics in econometrics, building on the foundational concepts introduced in the two compulsory econometrics courses for master students. It focuses on three distinct areas. First, the course treats causal inference and introduces the potential outcomes framework and concepts like Randomized Controlled Trial (RCT) and natural experiment. As part of this, it analyzes quasi-experimental empirical methods, such as Regression Discontinuity Design (RDD), Difference-in- Differences (DiD), matching methods and advanced Instrumental Variables (IV) methods. Second, the course deals with multivariate and nonlinear time series models. This includes Vector Autoregressions (VARs), Dynamic Factor Models (DFMs) and models with Time-Varying Parameters (TVPs) (like regime-switching-, stochastic volatility- and conditional heteroskedasticity-models). It also encompasses a discussion of cointegration. Third, the course introduces Machine Learning methods and nonparametric estimation. This includes Kernel Smoothing Methods, Regression Trees and Random Forests, Neural Networks and Classification Analysis. Assessment is based on bi-weekly problem sets and an individual project, where students apply a method from the course to their application of interest.
</abstr>
